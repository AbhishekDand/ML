{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CatDog Classification.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyPHiMZ5dblUuQ8EKzCw+wxI",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AbhishekDand/ML/blob/master/CatDog_Classification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lWOWxu12qZO8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.models import Sequential"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sUsopLeqqgD_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.layers import Conv2D\n",
        "from keras.layers import MaxPooling2D, Flatten, Dense"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N78QvDYyqsli",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "classifier=Sequential()"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jomtLQd4qvKN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "classifier.add(Conv2D(32,(3,3),input_shape=(64,64,3),activation='relu'))"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "il4Xgn1BrSPX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "classifier.add(MaxPooling2D(pool_size=(2,2)))"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dAyw7SsorlzM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "classifier.add(Conv2D(32,(3,3),activation='relu'))"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ai28ztFyrvWq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "classifier.add(MaxPooling2D(pool_size=(2,2)))"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MaZqb4uZsKQq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "classifier.add(Flatten())"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E0z9a_41sO9P",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "classifier.add(Dense(units=120,activation='relu'))"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EJ1hKZLLsUdF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "classifier.add(Dense(units=1,activation='sigmoid'))"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lZRAsEYXsiLK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "classifier.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BOlrU5Giwya0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.preprocessing.image import ImageDataGenerator"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vO1bss3_w7nw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_datagen=ImageDataGenerator(rescale=1./255,shear_range=0.2, zoom_range=0.2, horizontal_flip=True)"
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bhOZmsyqxMzo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_datagen=ImageDataGenerator(rescale=1./255)"
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IQyw-rhWxVKY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Neey1tVTp6y0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "2340908f-bcd4-4fca-f1f6-cf18569aee00"
      },
      "source": [
        "!wget --no-check-certificate \\\n",
        "    https://storage.googleapis.com/mledu-datasets/cats_and_dogs_filtered.zip \\\n",
        "    -O /tmp/cats_and_dogs_filtered.zip"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-09-02 16:38:18--  https://storage.googleapis.com/mledu-datasets/cats_and_dogs_filtered.zip\n",
            "Resolving storage.googleapis.com (storage.googleapis.com)... 74.125.20.128, 74.125.28.128, 74.125.142.128, ...\n",
            "Connecting to storage.googleapis.com (storage.googleapis.com)|74.125.20.128|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 68606236 (65M) [application/zip]\n",
            "Saving to: ‘/tmp/cats_and_dogs_filtered.zip’\n",
            "\n",
            "/tmp/cats_and_dogs_ 100%[===================>]  65.43M   227MB/s    in 0.3s    \n",
            "\n",
            "2020-09-02 16:38:19 (227 MB/s) - ‘/tmp/cats_and_dogs_filtered.zip’ saved [68606236/68606236]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nKXVCyl1qFqc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "import zipfile\n",
        "\n",
        "local_zip = '/tmp/cats_and_dogs_filtered.zip'\n",
        "zip_ref = zipfile.ZipFile(local_zip, 'r')\n",
        "zip_ref.extractall('/tmp')\n",
        "zip_ref.close()"
      ],
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AcHdqXevqLDG",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "d5c552b3-6867-44d9-882a-1bdd5aebc37d"
      },
      "source": [
        "  training_set=train_datagen.flow_from_directory('/tmp/cats_and_dogs_filtered/train',target_size=(64,64),batch_size=32,class_mode='binary')"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 2000 images belonging to 2 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U1E26LB9rB4c",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "ed4dac27-8562-4542-acff-87cd0b445459"
      },
      "source": [
        "test_set=train_datagen.flow_from_directory('/tmp/cats_and_dogs_filtered/validation',target_size=(64,64),batch_size=32,class_mode='binary')"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 1000 images belonging to 2 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bY6OikuMrNGy",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "outputId": "70cb1aa6-88d1-4f10-8df3-ccaf8f01f2ff"
      },
      "source": [
        "classifier.fit_generator(training_set, steps_per_epoch=8000,epochs=15,validation_data=test_set, validation_steps=2000)"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/15\n",
            "  63/8000 [..............................] - ETA: 29:35 - loss: 0.7058 - accuracy: 0.5210WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 120000 batches). You may need to use the repeat() function when building your dataset.\n",
            "WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 2000 batches). You may need to use the repeat() function when building your dataset.\n",
            "  63/8000 [..............................] - 19s 296ms/step - loss: 0.7058 - accuracy: 0.5210 - val_loss: 0.6904 - val_accuracy: 0.5810\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7ff910b35198>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VI0i_n7Trgq1",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "f341209d-7b0e-4683-d7aa-caa4bf4613c7"
      },
      "source": [
        "import numpy as np\n",
        "from keras.preprocessing import image\n",
        "test_img=image.load_img('/content/download.jpg',target_size=(64,64))\n",
        "test_img=image.img_to_array(test_img)\n",
        "test_img=np.expand_dims(test_img,axis=0)\n",
        "result=classifier.predict(test_img)\n",
        "print(result[0][0])"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.006284654\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mCnRR7FgtvSk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}